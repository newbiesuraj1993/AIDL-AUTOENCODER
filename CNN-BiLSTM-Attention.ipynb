{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640502fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.datasets import imdb \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4e5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Embedding, Dropout, Flatten, Layer, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eb144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models,layers,activations,losses,optimizers,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d51b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "lm = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9f2125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07a1daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a65f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = 10000\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b890a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a1daf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d416e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pure bilstm\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121df98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train, validation_split = 0.2,epochs = 12, verbose = True,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9169940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(Attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "402d56ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_12 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 192, 32)           36896     \n",
      "                                                                 \n",
      " maxpool1d_1 (MaxPooling1D)  (None, 12, 32)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 32)            0         \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 12, 128)          49664     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " attention_9 (Attention)     (None, 128)               140       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,370,861\n",
      "Trainable params: 90,861\n",
      "Non-trainable params: 1,280,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(200, ))\n",
    "x = Embedding(10000, 128, trainable=False)(inp)\n",
    "conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout_1)\n",
    "x = Attention()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdca7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aea9e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85c53005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#file_path = 'model.hdf5'\n",
    "#ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afb92c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 19s 179ms/step - loss: 0.6889 - accuracy: 0.5337 - val_loss: 0.6628 - val_accuracy: 0.5972\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 14s 173ms/step - loss: 0.6039 - accuracy: 0.6755 - val_loss: 0.5384 - val_accuracy: 0.7326\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 14s 174ms/step - loss: 0.5147 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7514\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.4641 - accuracy: 0.7862 - val_loss: 0.4748 - val_accuracy: 0.7680\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 0.4103 - accuracy: 0.8184 - val_loss: 0.4901 - val_accuracy: 0.7654\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 14s 183ms/step - loss: 0.3811 - accuracy: 0.8316 - val_loss: 0.4464 - val_accuracy: 0.7908\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 0.3389 - accuracy: 0.8550 - val_loss: 0.4554 - val_accuracy: 0.7880\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 0.3048 - accuracy: 0.8723 - val_loss: 0.4542 - val_accuracy: 0.7882\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 15s 186ms/step - loss: 0.2877 - accuracy: 0.8822 - val_loss: 0.4774 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15449a1e7d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5590cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea5476aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08d3df64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "260d0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1a45ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77     12500\n",
      "           1       0.75      0.87      0.80     12500\n",
      "\n",
      "    accuracy                           0.79     25000\n",
      "   macro avg       0.80      0.79      0.79     25000\n",
      "weighted avg       0.80      0.79      0.79     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0fbea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('Data_set.txt',delimiter = \"\\t\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5e5b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what's surprising about this traditional thril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the essential problem in orange county is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a devastating indictment of unbridled greed an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a breezy romantic comedy that has the punch of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>drumline ably captures the complicated relatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                        Description\n",
       "0       0  what's surprising about this traditional thril...\n",
       "1       0  the essential problem in orange county is that...\n",
       "2       1  a devastating indictment of unbridled greed an...\n",
       "3       1  a breezy romantic comedy that has the punch of...\n",
       "4       1  drumline ably captures the complicated relatio..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3eaab971",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df['Rating']\n",
    "X = new_df['Description']\n",
    "def clean_data(data):\n",
    "    data = data.replace(\"\\n\", \"\")\n",
    "    data = re.sub(r'\\W', ' ', data)\n",
    "    data = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data)\n",
    "    data = re.sub(r'\\s+', ' ', data, flags=re.I)\n",
    "    data = data.lower().split(\" \")\n",
    "    data = [word for word in data if word not in set(stopwords.words(\"english\"))]                                            \n",
    "    data = ' '.join([str(elem) for elem in data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80c7474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20368\\2672807160.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[incrementer]=i\n"
     ]
    }
   ],
   "source": [
    "incrementer=0\n",
    "for i in X:\n",
    "    i = clean_data(i)\n",
    "    X[incrementer]=i\n",
    "    incrementer+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "609ca464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20368\\3635973817.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[incrementer]=lemmatized_string\n"
     ]
    }
   ],
   "source": [
    "incrementer=0\n",
    "for i in X:\n",
    "    listw = nltk.word_tokenize(i)\n",
    "    lemmatized_string = ' '.join([lm.lemmatize(words) for words in listw])\n",
    "    X[incrementer]=lemmatized_string\n",
    "    incrementer+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2757e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4baf01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[745, 291, 88, 746, 122, 549, 350, 69, 519, 3, 216, 401]\n",
      "14436\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "print(X_train[0])\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2e76e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 200\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3426fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14436"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d99e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_15 (Embedding)    (None, 200, 128)          1847808   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 192, 32)           36896     \n",
      "                                                                 \n",
      " maxpool1d_1 (MaxPooling1D)  (None, 12, 32)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 32)            0         \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 12, 128)          49664     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " attention_12 (Attention)    (None, 128)               140       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,938,669\n",
      "Trainable params: 90,861\n",
      "Non-trainable params: 1,847,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(200, ))\n",
    "x = Embedding(14436, 128, trainable=False)(inp)\n",
    "conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout_1)\n",
    "x = Attention()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c0173c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 10s 51ms/step - loss: 0.6903 - accuracy: 0.5439 - val_loss: 0.6881 - val_accuracy: 0.5506\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.6903 - accuracy: 0.5457 - val_loss: 0.6890 - val_accuracy: 0.5506\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.6892 - accuracy: 0.5444 - val_loss: 0.6890 - val_accuracy: 0.5506\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6723 - accuracy: 0.5813 - val_loss: 0.6868 - val_accuracy: 0.5638\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6229 - accuracy: 0.6534 - val_loss: 0.7013 - val_accuracy: 0.5581\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.5626 - accuracy: 0.7042 - val_loss: 0.7231 - val_accuracy: 0.5631\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.5051 - accuracy: 0.7378 - val_loss: 0.7885 - val_accuracy: 0.5688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154762e3070>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es\n",
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "efc2f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "65731c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08f5b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67      1492\n",
      "           1       0.54      0.38      0.45      1174\n",
      "\n",
      "    accuracy                           0.58      2666\n",
      "   macro avg       0.57      0.56      0.56      2666\n",
      "weighted avg       0.58      0.58      0.57      2666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e64f88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv('C:/Users/HP/IMDB Dataset/IMDB Dataset.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d56afb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb['review'] = df_imdb['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "61a7ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1efea6de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m data_without_stopwords \u001b[38;5;241m=\u001b[39m remove_stopwords(df_imdb)\n\u001b[0;32m     10\u001b[0m data_without_stopwords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m data_without_stopwords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview without stopwords\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m cw : remove_tags(cw))\n\u001b[1;32m---> 11\u001b[0m data_without_stopwords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_review\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_without_stopwords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mstring\u001b[49m\u001b[38;5;241m.\u001b[39mpunctuation), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(df_imdb):\n",
    "    df_imdb['review without stopwords'] = df_imdb['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords.words(\"english\"))]))\n",
    "    return df_imdb\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "data_without_stopwords = remove_stopwords(df_imdb)\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a4b4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20368\\706899345.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a5352565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review without stopwords</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
       "      <td>wonderful little production  the filming techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's family little boy (jake) thi...</td>\n",
       "      <td>basically there s family little boy  jake  thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
       "      <td>petter mattei s  love time money  visually stu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                            review without stopwords  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...   \n",
       "1  wonderful little production. <br /><br />the f...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically there's family little boy (jake) thi...   \n",
       "4  petter mattei's \"love time money\" visually stu...   \n",
       "\n",
       "                                        clean_review  \n",
       "0  one reviewers mentioned watching 1 oz episode ...  \n",
       "1  wonderful little production  the filming techn...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there s family little boy  jake  thi...  \n",
       "4  petter mattei s  love time money  visually stu...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_stopwords.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "57b2d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewers mentioned watching 1 oz episode ...\n",
       "1        wonderful little production  the filming techn...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically there s family little boy  jake  thi...\n",
       "4        petter mattei s  love time money  visually stu...\n",
       "                               ...                        \n",
       "49995    thought movie right good job  creative origina...\n",
       "49996    bad plot  bad dialogue  bad acting  idiotic di...\n",
       "49997    catholic taught parochial elementary schools n...\n",
       "49998    i m going disagree previous comment side malti...\n",
       "49999    one expects star trek movies high art  fans ex...\n",
       "Name: clean_review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_without_stopwords.to_csv('IMDB Dataset/cleaned_data.csv')\n",
    "reviews = data_without_stopwords['clean_review']\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a648c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = []\n",
    "for i in range(len(reviews)):\n",
    "    reviews_list.append(reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fcc1010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = data_without_stopwords['sentiment']\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cca6e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2a7d87eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saw film birmingham southern college 1975  shown combination red balloon  films similar dream like quality  bulk film entails fish swimming happily bowl new owner  little boy  away school  cat enters room fish bowl are  begins warily stalk  prey   boy begins walk home school  viewer wonders whether arrive time save fish friend  fish becomes agitated cat s presence  finally jumps bowl  cat quickly walks fish  gently picks paws  returns bowl  boy returns happily fish  none wiser the ending amazing irony technical complexity  hard imagine director could ve pulled technical feat back 1959    seems trick 2003 if find it  watch    disappointed   do  find it  let know get copy  too '"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b6dd2250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cc0b3ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95417"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "     \n",
    "\n",
    "words_to_index = tokenizer.word_index\n",
    "     \n",
    "\n",
    "len(words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b7a28dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            curr_word = w_line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9991e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('C:/Users/HP/Downloads/glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bf300506",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 150\n",
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index, :] = embedding_vector\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e13d158b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding_27 (Embedding)    (None, 150, 50)           4770850   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 148, 512)          77312     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 49, 512)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 49, 512)           0         \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirecti  (None, 49, 64)           139520    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " attention_14 (Attention)    (None, 64)                113       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,989,908\n",
      "Trainable params: 219,058\n",
      "Non-trainable params: 4,770,850\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(150, ))\n",
    "x = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)(inp)\n",
    "conv_1 = Conv1D(512, 3, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(3)(conv_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "x = Bidirectional(LSTM(32, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout_1)\n",
    "x = Attention()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ea29e605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 150)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "     \n",
    "\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "649127dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "16a8991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "500/500 [==============================] - 139s 271ms/step - loss: 0.4892 - accuracy: 0.7623 - val_loss: 0.3939 - val_accuracy: 0.8211\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - 134s 268ms/step - loss: 0.3747 - accuracy: 0.8369 - val_loss: 0.3747 - val_accuracy: 0.8363\n",
      "Epoch 3/20\n",
      "500/500 [==============================] - 135s 271ms/step - loss: 0.3349 - accuracy: 0.8562 - val_loss: 0.3457 - val_accuracy: 0.8485\n",
      "Epoch 4/20\n",
      "500/500 [==============================] - 134s 269ms/step - loss: 0.3089 - accuracy: 0.8695 - val_loss: 0.3454 - val_accuracy: 0.8400\n",
      "Epoch 5/20\n",
      "500/500 [==============================] - 136s 271ms/step - loss: 0.2855 - accuracy: 0.8798 - val_loss: 0.3283 - val_accuracy: 0.8609\n",
      "Epoch 6/20\n",
      "500/500 [==============================] - 135s 271ms/step - loss: 0.2612 - accuracy: 0.8928 - val_loss: 0.3295 - val_accuracy: 0.8586\n",
      "Epoch 7/20\n",
      "500/500 [==============================] - 136s 271ms/step - loss: 0.2440 - accuracy: 0.8986 - val_loss: 0.3987 - val_accuracy: 0.8369\n",
      "Epoch 8/20\n",
      "500/500 [==============================] - 135s 270ms/step - loss: 0.2218 - accuracy: 0.9104 - val_loss: 0.3272 - val_accuracy: 0.8634\n",
      "Epoch 9/20\n",
      "500/500 [==============================] - 135s 270ms/step - loss: 0.2039 - accuracy: 0.9188 - val_loss: 0.4321 - val_accuracy: 0.8456\n",
      "Epoch 10/20\n",
      "500/500 [==============================] - 136s 271ms/step - loss: 0.1925 - accuracy: 0.9243 - val_loss: 0.3469 - val_accuracy: 0.8634\n",
      "Epoch 11/20\n",
      "500/500 [==============================] - 136s 272ms/step - loss: 0.1748 - accuracy: 0.9307 - val_loss: 0.4460 - val_accuracy: 0.8388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15402754340>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es\n",
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_indices, Y_train, batch_size=64, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7210885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d3a8b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0b811ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83      5035\n",
      "           1       0.78      0.95      0.86      4965\n",
      "\n",
      "    accuracy                           0.84     10000\n",
      "   macro avg       0.86      0.84      0.84     10000\n",
      "weighted avg       0.86      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc06ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
