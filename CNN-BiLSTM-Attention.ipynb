{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640502fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.datasets import imdb \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4e5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Embedding, Dropout, Flatten, Layer, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eb144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models,layers,activations,losses,optimizers,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a65f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = 10000\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b890a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "89d416e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 128)              98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pure bilstm\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "121df98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train, validation_split = 0.2,epochs = 12, verbose = True,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9169940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(Attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0ee0865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 192, 32)           36896     \n",
      "                                                                 \n",
      " maxpool1d_1 (MaxPooling1D)  (None, 12, 32)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 32)            0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 12, 128)          49664     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " attention_2 (Attention)     (None, 128)               140       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,370,861\n",
      "Trainable params: 90,861\n",
      "Non-trainable params: 1,280,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(200, ))\n",
    "x = Embedding(10000, 128, trainable=False)(inp)\n",
    "conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "dropout = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "#conv_2 = Conv1D(32, 7, activation='relu', name='conv1d_2')(dropout_1)\n",
    "#maxpool_2 = MaxPooling1D(8,padding='same', name='maxpool1d_2')(conv_2)\n",
    "#dropout_2 = Dropout(0.2, name='dropout_2')(maxpool_2)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout)\n",
    "x = Attention()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f4c25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b2119ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85c53005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#file_path = 'model.hdf5'\n",
    "#ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afb92c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 22s 195ms/step - loss: 0.6845 - accuracy: 0.5492 - val_loss: 0.6235 - val_accuracy: 0.6514\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 16s 197ms/step - loss: 0.5924 - accuracy: 0.6909 - val_loss: 0.5451 - val_accuracy: 0.7296\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 16s 198ms/step - loss: 0.5243 - accuracy: 0.7452 - val_loss: 0.5292 - val_accuracy: 0.7390\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 16s 201ms/step - loss: 0.4698 - accuracy: 0.7811 - val_loss: 0.5672 - val_accuracy: 0.7114\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 16s 196ms/step - loss: 0.4223 - accuracy: 0.8108 - val_loss: 0.4786 - val_accuracy: 0.7640\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 16s 196ms/step - loss: 0.3822 - accuracy: 0.8343 - val_loss: 0.5066 - val_accuracy: 0.7738\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 16s 204ms/step - loss: 0.3533 - accuracy: 0.8489 - val_loss: 0.4642 - val_accuracy: 0.7868\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 16s 199ms/step - loss: 0.3134 - accuracy: 0.8698 - val_loss: 0.4602 - val_accuracy: 0.7884\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 16s 203ms/step - loss: 0.2810 - accuracy: 0.8835 - val_loss: 0.4711 - val_accuracy: 0.7918\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 16s 200ms/step - loss: 0.2640 - accuracy: 0.8925 - val_loss: 0.4662 - val_accuracy: 0.7926\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 16s 199ms/step - loss: 0.2469 - accuracy: 0.8974 - val_loss: 0.4837 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d0185fed10>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5590cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea5476aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08d3df64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "260d0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1a45ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.78     12500\n",
      "           1       0.75      0.88      0.81     12500\n",
      "\n",
      "    accuracy                           0.80     25000\n",
      "   macro avg       0.80      0.80      0.79     25000\n",
      "weighted avg       0.80      0.80      0.79     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbea03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
