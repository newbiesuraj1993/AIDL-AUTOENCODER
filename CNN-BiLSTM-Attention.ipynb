{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640502fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.keras.datasets import imdb \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8e325ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4e5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional, Embedding, Dropout, Flatten, Layer, Input, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eb144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models,layers,activations,losses,optimizers,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86d51b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "lm = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import metrics, svm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e258078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9f2125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07a1daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a65f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_words = 10000\n",
    "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=n_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b890a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a1daf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d416e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pure bilstm\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121df98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train, validation_split = 0.2,epochs = 12, verbose = True,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9169940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(Attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60c7d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_12 (Embedding)    (None, 200, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 192, 32)           36896     \n",
      "                                                                 \n",
      " maxpool1d_1 (MaxPooling1D)  (None, 12, 32)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 32)            0         \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 12, 128)          49664     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " attention_9 (Attention)     (None, 128)               140       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,370,861\n",
      "Trainable params: 90,861\n",
      "Non-trainable params: 1,280,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(200, ))\n",
    "x = Embedding(10000, 128, trainable=False)(inp)\n",
    "conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout_1)\n",
    "x = Attention()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdca7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aea9e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85c53005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#file_path = 'model.hdf5'\n",
    "#ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afb92c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 19s 179ms/step - loss: 0.6889 - accuracy: 0.5337 - val_loss: 0.6628 - val_accuracy: 0.5972\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 14s 173ms/step - loss: 0.6039 - accuracy: 0.6755 - val_loss: 0.5384 - val_accuracy: 0.7326\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 14s 174ms/step - loss: 0.5147 - accuracy: 0.7505 - val_loss: 0.5073 - val_accuracy: 0.7514\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 14s 176ms/step - loss: 0.4641 - accuracy: 0.7862 - val_loss: 0.4748 - val_accuracy: 0.7680\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 14s 181ms/step - loss: 0.4103 - accuracy: 0.8184 - val_loss: 0.4901 - val_accuracy: 0.7654\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 14s 183ms/step - loss: 0.3811 - accuracy: 0.8316 - val_loss: 0.4464 - val_accuracy: 0.7908\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 0.3389 - accuracy: 0.8550 - val_loss: 0.4554 - val_accuracy: 0.7880\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 15s 184ms/step - loss: 0.3048 - accuracy: 0.8723 - val_loss: 0.4542 - val_accuracy: 0.7882\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 15s 186ms/step - loss: 0.2877 - accuracy: 0.8822 - val_loss: 0.4774 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15449a1e7d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5590cdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea5476aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08d3df64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "260d0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1a45ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77     12500\n",
      "           1       0.75      0.87      0.80     12500\n",
      "\n",
      "    accuracy                           0.79     25000\n",
      "   macro avg       0.80      0.79      0.79     25000\n",
      "weighted avg       0.80      0.79      0.79     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0fbea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('Data_set.txt',delimiter = \"\\t\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5e5b556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what's surprising about this traditional thril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the essential problem in orange county is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a devastating indictment of unbridled greed an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a breezy romantic comedy that has the punch of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>drumline ably captures the complicated relatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                        Description\n",
       "0       0  what's surprising about this traditional thril...\n",
       "1       0  the essential problem in orange county is that...\n",
       "2       1  a devastating indictment of unbridled greed an...\n",
       "3       1  a breezy romantic comedy that has the punch of...\n",
       "4       1  drumline ably captures the complicated relatio..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3eaab971",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df['Rating']\n",
    "X = new_df['Description']\n",
    "def clean_data(data):\n",
    "    data = data.replace(\"\\n\", \"\")\n",
    "    data = re.sub(r'\\W', ' ', data)\n",
    "    data = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data)\n",
    "    data = re.sub(r'\\s+', ' ', data, flags=re.I)\n",
    "    data = data.lower().split(\" \")\n",
    "    data = [word for word in data if word not in set(stopwords.words(\"english\"))]                                            \n",
    "    data = ' '.join([str(elem) for elem in data])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80c7474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20368\\2672807160.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[incrementer]=i\n"
     ]
    }
   ],
   "source": [
    "incrementer=0\n",
    "for i in X:\n",
    "    i = clean_data(i)\n",
    "    X[incrementer]=i\n",
    "    incrementer+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "609ca464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20368\\3635973817.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[incrementer]=lemmatized_string\n"
     ]
    }
   ],
   "source": [
    "incrementer=0\n",
    "for i in X:\n",
    "    listw = nltk.word_tokenize(i)\n",
    "    lemmatized_string = ' '.join([lm.lemmatize(words) for words in listw])\n",
    "    X[incrementer]=lemmatized_string\n",
    "    incrementer+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2757e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#sentences_train, sentences_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4baf01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[745, 291, 88, 746, 122, 549, 350, 69, 519, 3, 216, 401]\n",
      "14436\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(sentences_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "print(X_train[0])\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2e76e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 200\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3426fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14436"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d99e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_15 (Embedding)    (None, 200, 128)          1847808   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 192, 32)           36896     \n",
      "                                                                 \n",
      " maxpool1d_1 (MaxPooling1D)  (None, 12, 32)            0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 32)            0         \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 12, 128)          49664     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " attention_12 (Attention)    (None, 128)               140       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,938,669\n",
      "Trainable params: 90,861\n",
      "Non-trainable params: 1,847,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(200, ))\n",
    "x = Embedding(14436, 128, trainable=False)(inp)\n",
    "conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout_1)\n",
    "x = Attention()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c0173c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 10s 51ms/step - loss: 0.6903 - accuracy: 0.5439 - val_loss: 0.6881 - val_accuracy: 0.5506\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.6903 - accuracy: 0.5457 - val_loss: 0.6890 - val_accuracy: 0.5506\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.6892 - accuracy: 0.5444 - val_loss: 0.6890 - val_accuracy: 0.5506\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6723 - accuracy: 0.5813 - val_loss: 0.6868 - val_accuracy: 0.5638\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.6229 - accuracy: 0.6534 - val_loss: 0.7013 - val_accuracy: 0.5581\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.5626 - accuracy: 0.7042 - val_loss: 0.7231 - val_accuracy: 0.5631\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.5051 - accuracy: 0.7378 - val_loss: 0.7885 - val_accuracy: 0.5688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x154762e3070>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es\n",
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "efc2f503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "65731c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08f5b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67      1492\n",
      "           1       0.54      0.38      0.45      1174\n",
      "\n",
      "    accuracy                           0.58      2666\n",
      "   macro avg       0.57      0.56      0.56      2666\n",
      "weighted avg       0.58      0.58      0.57      2666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36106fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv('C:/Users/HP/IMDB Dataset/IMDB Dataset.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a28c35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97f4ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb['review'] = df_imdb['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54ae3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3044a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df_imdb):\n",
    "    df_imdb['review without stopwords'] = df_imdb['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords.words(\"english\"))]))\n",
    "    return df_imdb\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "\n",
    "def stringprocess(text):\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r\"\\#\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+\",\"URL\", text)\n",
    "    text = re.sub(r\"@\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9()!?\\'\\`\\\"]\", \" \", text)\n",
    "    text = re.sub(r'[^\\w\\d\\s\\']+', '', text)\n",
    "    text = re.sub(\"\\s{2,}\", \" \", text)\n",
    "    text = text.strip(' ')\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edcd5052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_21620\\3584704324.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "data_without_stopwords = remove_stopwords(df_imdb)\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : stringprocess(cw))\n",
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28492fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_stopwords.to_csv('IMDB Dataset/cleaned_data.csv')\n",
    "reviews = data_without_stopwords['clean_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9317213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def stopwords_removal(sent):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    word_tokens = word_tokenize(sent)\n",
    "   \n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "   \n",
    "    filtered_sentence = []\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    newsent = ' '.join(filtered_sentence)\n",
    "\n",
    "    #print(word_tokens)\n",
    "    return newsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c54667e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner_reviews_list = []\n",
    "for i in data_without_stopwords['clean_review']:\n",
    "    new_sent = stopwords_removal(i)\n",
    "    #new_sent = re.sub(r\"br\", \" \", new_sent)\n",
    "    new_sent = remove_tags(new_sent)\n",
    "    new_sent = stringprocess(new_sent)\n",
    "    cleaner_reviews_list.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c23e5024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewers mentioned watching 1 oz episode hooked right exactly happened br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many aryans muslims gangstas latinos christians italians irish scuffles death stares dodgy dealings shady agreements never far away br br would say main appeal show due fact goes shows dare forget pretty pictures painted mainstream audiences forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards sold nickel inmates kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_reviews_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12a7bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:     \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f661c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = []\n",
    "for i in range(len(cleaner_reviews_list)):\n",
    "    cleaned_singles = ' '.join( [w for w in cleaner_reviews_list[i].split() if len(w)>1] )\n",
    "    cleaned_singles = ''.join([i for i in cleaned_singles if not i.isdigit()])\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(cleaned_singles))\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:       \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "    reviews_list.append(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ad78ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list_cl = []\n",
    "for i in reviews_list:\n",
    "    i = re.sub(r\"br\", \"\", i)\n",
    "    reviews_list_cl.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62f372b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mention watch oz episode hook right exactly happen   first thing strike oz utality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word   call oz nickname give oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangstas latinos christian italian irish scuffle death stare dodgy dealing shady agreement never far away   would say main appeal show due fact go show dare forget pretty picture paint mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watch developed taste oz get accustomed high level graphic violence violence injustice crook guard sell nickel inmate kill order get away well mannered middle class inmate turn prison bitch due lack street skill prison experience watch oz may become comfortable uncomfortable view thats get touch darker side'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_list_cl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f262985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = data_without_stopwords['sentiment']\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c3230a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list_cl, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f6e6209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saw film birmingham southern college show combination red balloon film similar dream like quality bulk film entail fish swim happily bowl new owner little boy away school cat enters room fish bowl begin warily stalk prey boy begin walk home school viewer wonder whether arrive time save fish friend fish becomes agitate cat presence finally jump bowl cat quickly walk fish gently pick paws return bowl boy return happily fish none wiser   end amazing irony technical complexity hard imagine director could pull technical feat back seem trick   find watch disappoint find let know get copy'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b100622a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a6e15254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81167"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "     \n",
    "\n",
    "words_to_index = tokenizer.word_index\n",
    "     \n",
    "\n",
    "len(words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "67abe802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            curr_word = w_line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a7fc0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('C:/Users/HP/Downloads/glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d001b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 150\n",
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index, :] = embedding_vector\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "85af26f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 150, 50)           4058350   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 148, 256)          38656     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 49, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 49, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 49, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " attention_5 (Attention)     (None, 256)               305       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,508,064\n",
      "Trainable params: 449,714\n",
      "Non-trainable params: 4,058,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inp = Input(shape=(150, ))\n",
    "x = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)(inp)\n",
    "conv_1 = Conv1D(256, 3, activation='relu', name='conv1d_1')(x)\n",
    "maxpool_1 = MaxPooling1D(3)(conv_1)\n",
    "dropout_1 = Dropout(0.2, name='dropout')(maxpool_1)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(dropout_1)\n",
    "x = Attention()(x)\n",
    "#x = tf.expand_dims(x, axis=2)\n",
    "#x = Bidirectional(LSTM(64, return_sequences=True, dropout=0.25,recurrent_dropout=0.25))(x)\n",
    "#x = Attention()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "adcfa9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 150)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "     \n",
    "\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b8d97bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8c7ce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 250s 988ms/step - loss: 0.5101 - accuracy: 0.7481 - val_loss: 0.4184 - val_accuracy: 0.8133\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 265s 1s/step - loss: 0.3987 - accuracy: 0.8212 - val_loss: 0.3788 - val_accuracy: 0.8328\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 273s 1s/step - loss: 0.3684 - accuracy: 0.8383 - val_loss: 0.3704 - val_accuracy: 0.8386\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.3424 - accuracy: 0.8499 - val_loss: 0.3612 - val_accuracy: 0.8367\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 277s 1s/step - loss: 0.3265 - accuracy: 0.8607 - val_loss: 0.3427 - val_accuracy: 0.8504\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 277s 1s/step - loss: 0.3098 - accuracy: 0.8687 - val_loss: 0.3478 - val_accuracy: 0.8536\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 292s 1s/step - loss: 0.2927 - accuracy: 0.8772 - val_loss: 0.3322 - val_accuracy: 0.8535\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 274s 1s/step - loss: 0.2799 - accuracy: 0.8832 - val_loss: 0.3605 - val_accuracy: 0.8425\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 275s 1s/step - loss: 0.2709 - accuracy: 0.8902 - val_loss: 0.3389 - val_accuracy: 0.8506\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 275s 1s/step - loss: 0.2540 - accuracy: 0.8964 - val_loss: 0.3393 - val_accuracy: 0.8595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cc32801c0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def callbacks(**kwargs):\n",
    "    mc = ModelCheckpoint(filepath = kwargs.get(\"filename\"), save_best_only = True, verbose = 0)\n",
    "    es = EarlyStopping(monitor = kwargs.get(\"monitor\"), patience = kwargs.get(\"patience\"))\n",
    "    return mc,es\n",
    "mc,es = callbacks(filename = \"./cnn_bilstm.h5\", patience = 3, monitor = \"val_loss\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train_indices, Y_train, batch_size=128, epochs=20, validation_split=0.2,callbacks=[mc,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f50b7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9fe4e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_p = (y_pred > 0.5).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "81ab5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      5035\n",
      "           1       0.85      0.88      0.87      4965\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87492d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
